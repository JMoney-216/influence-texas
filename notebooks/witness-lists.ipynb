{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The purpose of this notebook is to get a CSV of tabular data based on the witness lists.\n",
    "\n",
    "# I used wget to collect ftp.legis.state.tx.us/bills/85R/witlistbill/html/senate_bills/\n",
    "# and put them all together in a directory called '/bills/85R/witlistbill/html/senate_bills/'\n",
    "# These files are not being stored in the github repo because they're too big.\n",
    "\n",
    "# The published lists are in HTML exported from Microsoft Word, so the markup reflects \n",
    "# intended page layout rather than content.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endWithState = re.compile(r'[^\\(](AL|AK|AS|AZ|AR|CA|CO|CT|DE|DC|FM|FL|GA|GU|HI|ID|IL|IN|IA|KS|KY|LA|ME|MH|MD|MA|MI|MN|MS|MO|MT|NE|NV|NH|NJ|NM|NY|NC|ND|MP|OH|OK|OR|PW|PA|PR|RI|SC|SD|TN|TX|Texas|UT|VT|VI|VA|WA|WV|WI|WY)\\n?$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parks', 'Ursula']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addName(line):\n",
    "    flags = [re.IGNORECASE, re.DOTALL]\n",
    "    regexes = [r\"^((?:[\\w\\'\\-]+\\s)*[\\w\\'\\-]+),\\n((?:\\w+\\s)*\\w+)\\xa0\\xa0 \", \n",
    "              r\"^((?:[\\w\\'\\-]+\\s)*[\\w\\'\\-]+),\\n((?:\\w+\\s)*\\w+)\\s+\\(\", \n",
    "              r\"^((?:[\\w\\'\\-]+\\s)*[\\w\\'\\-]+),[\\n\\s]+((?:[A-Z]\\.)+)\\s\\s\",\n",
    "              r'^((?:\\w+\\s)*\\w+),\\s+([^\\(\\s]+) ', \n",
    "              r'^((?:\\w+\\s)*\\w+),\\s+((?:\\w+\\s)*\\w+)  '] # third one for initials as first name\n",
    "    partial = r'^(\\w+)\\s+\\n\\('  # Matches where someone put just a surname\n",
    "    for f in flags:\n",
    "        for r in regexes:\n",
    "            nameRe = re.compile(r, f)\n",
    "            match = re.search(nameRe, line[0])\n",
    "            if match:\n",
    "                extension = [match.group(1).strip(), match.group(2).strip()]\n",
    "                return extension\n",
    "    \n",
    "    # A separate case for the partial match\n",
    "    nameRe = re.compile(partial)\n",
    "    if re.search(nameRe, line[0]):\n",
    "        match = re.search(nameRe, line[0])\n",
    "        extension = [match.group(1).strip(), None]\n",
    "        return extension\n",
    "    \n",
    "    # And a third case to leave the fields blank\n",
    "    extension = [None, None]\n",
    "    return extension\n",
    "\n",
    "def addTitle(line):\n",
    "    regexes = [r',\\s(?:(?:\\w+\\s)*\\w+)\\s+(.+)\\s*\\(also providing', r',\\s(?:(?:\\w+\\s)*\\w+)\\s+(.+)\\s*\\(',\n",
    "               '^(?:(?:\\w+\\s)*\\w+),\\s+(?:(?:\\w+\\s)*\\w+)\\s\\s+(.+)\\(also providing',\n",
    "               '^(?:(?:\\w+\\s)*\\w+),\\s+(?:(?:\\w+\\s)*\\w+)\\s\\s+(.+)\\('\n",
    "              #  r'^.+,\\n.+\\s+(.+)\\s+\\(also providing', r'^.+,\\n.+\\s+(.+)\\s+\\(',\n",
    "              # ',\\n?.+\\xa0\\xa0 ((?:\\w+\\s)*\\w+)\\s+(\\(also providing written testimony\\))?\\s+\\('\n",
    "              ]\n",
    "    for r in regexes:\n",
    "        titleRe = re.compile(r)\n",
    "        match = re.search(titleRe, line[0])\n",
    "        if match:\n",
    "            extension = [match.group(1).strip()]\n",
    "            return extension\n",
    "    extension = [None]\n",
    "    return extension\n",
    "\n",
    "def addOrg(line):\n",
    "    flags = [re.IGNORECASE, re.DOTALL]\n",
    "    regexes = [r'written testimony\\)\\s+\\((.+)\\)\\s*(,|$)', \n",
    "              r'\\s+\\((.+)\\)\\s*(,|$)',]\n",
    "    for f in flags:\n",
    "        for r in regexes:\n",
    "            orgRe = re.compile(r, f)\n",
    "            match = re.search(orgRe, line[0])\n",
    "            if match:\n",
    "                extension = [match.group(1).strip()]\n",
    "                return extension\n",
    "    extension = [None]\n",
    "    return extension\n",
    "\n",
    "def addCity(line):\n",
    "    extension = [None, None]\n",
    "    cityRe = re.compile(r'\\)\\s?,\\s(.*),\\s(.*)$')\n",
    "    match = re.search(cityRe, line[0])\n",
    "    if match:\n",
    "        extension = [match.group(1).strip(), match.group(2).strip()]\n",
    "    return extension\n",
    "\n",
    "addName([\"Parks,\\nUrsula (Legislative Budget Board)\",\"HB 2\",\"For\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I haven't made a corresponding function for Senate bills. Instead I\n",
    "# reused this same function, which means the Senate data probably has\n",
    "# more errors.\n",
    "\n",
    "def HBWitness(witnessList):\n",
    "    fp = open(witnessList, encoding = 'cp1252')\n",
    "    soup = BeautifulSoup(fp.read(), \"html.parser\")\n",
    "    \n",
    "    # each printed page has a class with Wordsection plus a number\n",
    "    pages = soup.select(\"div[class^=WordSection]\") \n",
    "    \n",
    "    indent = re.compile(r\"^\\s{30}\") # whitespace should mean it's a listing, page number, or the heading \"WITNESS LIST\"\n",
    "    forStance = re.compile(r'^\\s+FOR\\s?:', re.IGNORECASE) # i flag means case-insensitive\n",
    "    againstStance = re.compile(r'^\\s+AGAINST\\s?:', re.IGNORECASE)\n",
    "    onStance = re.compile(r'^\\s+ON\\s?:', re.IGNORECASE)\n",
    "\n",
    "    wit = []\n",
    "    stance = \"For\"\n",
    "    for page in pages:\n",
    "        witpage = []\n",
    "        pp = page.select(\"p\")\n",
    "        for line in pp:\n",
    "            text = line.get_text()\n",
    "            if re.match(forStance, text):\n",
    "                stance = \"For\"\n",
    "            if re.match(againstStance, text):\n",
    "                stance = \"Against\"\n",
    "            if re.match(onStance, text):\n",
    "                stance = \"On\"\n",
    "            if re.match(indent, text):\n",
    "                witpage.append([line.get_text(), stance])\n",
    "        wit.extend(witpage[1:-1])\n",
    "\n",
    "    bill = soup.find('span', {'style':\"color:windowtext;text-decoration:none\"}) # identifies the bill\n",
    "    bill = bill.get_text()\n",
    "    for line in wit:\n",
    "        line.extend([bill.strip()])\n",
    "    \n",
    "    wit = [x for x in wit if x != None]\n",
    "    \n",
    "    return wit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mergelines(wit):\n",
    "    changed = 0    \n",
    "    newList = []\n",
    "    badList = []\n",
    "    tooShort = re.compile(\"^\\w+\\)?,?\\s?(AL|AK|AS|AZ|AR|CA|CO|CT|DE|DC|FM|FL|GA|GU|HI|ID|IL\\\n",
    "                        |IN|IA|KS|KY|LA|ME|MH|MD|MA|MI|MN|MS|MO|MT|NE|NV|NH|NJ|NM|NY|NC\\\n",
    "                        |ND|MP|OH|OK|OR|PW|PA|PR|RI|SC|SD|TN|TX|Texas|UT|VT|VI|VA|WA|WV|WI|WY)?\\n?$\") # line shouldn't have just one word\n",
    "    for line in wit:\n",
    "        line[0] = line[0].strip()\n",
    "    \n",
    "    for line in wit[:-1]:\n",
    "        lineIndex = wit.index(line)\n",
    "        \n",
    "        # Lines will get merged if they pass any of the three tests. Only if not will a line be accepted.\n",
    "        \n",
    "        if re.search(endWithState, wit[lineIndex + 1][0]) and not re.search(endWithState, line[0]) \\\n",
    "        and addName(line) != [None, None] and addName(wit[lineIndex + 1]) == [None, None]:\n",
    "            newList.append([line[0] + \" \" + wit[lineIndex + 1][0], line[1], line[2]])\n",
    "            badList.append(wit[lineIndex + 1][0:3])\n",
    "            changed += 1\n",
    "        \n",
    "        elif re.search(tooShort, wit[lineIndex + 1][0].strip()):\n",
    "            newList.append([line[0] + \" \" + wit[lineIndex + 1][0], line[1], line[2]])\n",
    "            badList.append(wit[lineIndex + 1][0:3])\n",
    "            changed += 1\n",
    "            \n",
    "        elif line[0].count(')') != line[0].count('(') \\\n",
    "        and wit[lineIndex + 1][0].count(')') != wit[lineIndex + 1][0].count('(') \\\n",
    "        and addName(line) != [None, None] and not re.search(endWithState, line[0]):\n",
    "            newList.append([line[0] + \" \" + wit[lineIndex + 1][0], line[1], line[2]])\n",
    "            badList.append(wit[lineIndex + 1][0:3])\n",
    "            changed += 1\n",
    "            \n",
    "        elif line[0].count(')') != line[0].count('(') \\\n",
    "        and wit[lineIndex + 1][0].count(')') != wit[lineIndex + 1][0].count('(') \\\n",
    "        and addName(line) != [None, None] \\\n",
    "        and addName(wit[lineIndex + 1]) == [None,None]:\n",
    "            newList.append([line[0] + \" \" + wit[lineIndex + 1][0], line[1], line[2]])\n",
    "            badList.append(wit[lineIndex + 1][0:3])\n",
    "            changed += 1\n",
    "            \n",
    "        else:\n",
    "            newList.append(line[0:3])\n",
    "    \n",
    "    answer = [x for x in newList if x not in badList]\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "def extractRows(folderName):\n",
    "    \n",
    "    houseWit = []\n",
    "    for folderName, subfolders, filenames in os.walk(folderName):\n",
    "        for filename in filenames:\n",
    "            if filename != \".DS_Store\":\n",
    "                source = folderName + filename\n",
    "                wit = HBWitness(source)\n",
    "                # print(str(changed) + \" lines changed.\")\n",
    "                houseWit.extend(wit)\n",
    "    return houseWit\n",
    "            \n",
    "folderName = 'bills/85R/witlistbill/html/house_bills/'\n",
    "houseWit = extractRows(folderName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# houseWit[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trying to rejoin entries split across lines\n",
    "newList = mergelines(houseWit)\n",
    "\n",
    "newList = mergelines(newList) # Will doing it twice catch 3-line entries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the last six fields to each row\n",
    "\n",
    "for line in newList:\n",
    "    line.extend(addName(line))\n",
    "    line.extend(addTitle(line))\n",
    "    line.extend(addOrg(line))\n",
    "    line.extend(addCity(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pandas is only used for data exploration. \n",
    "# There are definitely still errors.\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "\n",
    "df = pd.DataFrame(newList, columns=list(['raw', 'position', 'bill', 'last','first','title', 'org','city','state']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['bill'] == \"HB 3025\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the lines most likely to have problems\n",
    "\n",
    "df[pd.isnull(df['org'])]\n",
    "# df.first.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['bill'] == \"HB 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at a random sample\n",
    "\n",
    "df.sample(n = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeN(cell):\n",
    "    if cell != None:\n",
    "        cell = cell.replace(\"\\n\", \" \")\n",
    "    return cell\n",
    "    \n",
    "newList = [[changeN(cell) for cell in line] for line in newList]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def export(dir, witList):\n",
    "    with open(dir,'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['FullText', 'Position', 'Bill', 'LastName', 'FirstName', 'Role', 'Organization', 'City', 'State'])\n",
    "        writer.writerows(witList) # better just to include the text maybe.\n",
    "    return None\n",
    "\n",
    "houseDir = '../data/witness-lists/HouseWitness.csv'\n",
    "export(houseDir, newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# duplicating the House process for the Senate\n",
    "\n",
    "folderName = 'bills/85R/witlistbill/html/senate_bills/'\n",
    "senateWit = extractRows(folderName)\n",
    "senList = mergelines(senateWit)\n",
    "senList = mergelines(senList)\n",
    "for line in senList:\n",
    "    line.extend(addName(line))\n",
    "    line.extend(addTitle(line))\n",
    "    line.extend(addOrg(line))\n",
    "    line.extend(addCity(line))\n",
    "senList = [[changeN(cell) for cell in line] for line in senList]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "senateDir = '../data/witness-lists/SenateWitness.csv'\n",
    "export(senateDir, senList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just looking at a sample of the data. Maybe 95% correct.\n",
    "\n",
    "sen = pd.DataFrame(senList, columns=list(['raw', 'position', 'bill', 'last','first','title', 'org','city','state']))\n",
    "sen.sample(n = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
